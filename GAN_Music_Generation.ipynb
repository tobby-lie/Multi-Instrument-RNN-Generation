{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caEhtUelyEzN",
        "colab_type": "text"
      },
      "source": [
        "# **Mount google drive folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0EezHZtwBtz",
        "colab_type": "code",
        "outputId": "c982ad4f-8d5c-4c42-b778-c98118cfd78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao_bPrtkUHiP",
        "colab_type": "text"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ED7rdqpzfdz",
        "colab_type": "code",
        "outputId": "07558aa8-76b3-4d1e-8985-a6c43c01d1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from music21 import converter, instrument, note, chord, stream\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dense, Bidirectional, CuDNNLSTM, LeakyReLU, BatchNormalization, Reshape, Input\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from IPython.display import HTML, display"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIn0FhId1wsS",
        "colab_type": "text"
      },
      "source": [
        "# **Print the files in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG_HhPUT1xIP",
        "colab_type": "code",
        "outputId": "c59f3190-c654-48c6-e186-a8a083098171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "print(os.listdir('/content/gdrive/My Drive/MIDI'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['5_rock_180_beat_4-4.mid', '6_blues-shuffle_134_beat_4-4.mid', '6_funk_91_beat_4-4.mid', '6_funk_80_beat_4-4.mid', '6_dance-disco_120_beat_4-4.mid', '6_jazz-funk_116_fill_4-4.mid', '6_jazz-swing_215_beat_4-4.mid', '6_latin-brazilian-maracatu_96_beat_4-4.mid', '6_neworleans-secondline_99_beat_4-4.mid', '6_rock_60_fill_4-4.mid', '6_rock_86_fill_4-4.mid', '1_jazz-swing_124_beat_4-4.mid', '1_latin-venezuelan-sangueo_101_beat_4-4.mid', '1_funk_92_beat_4-4.mid', '1_funk_95_beat_4-4.mid', '1_funk_80_beat_4-4.mid', '1_latin-chacarera_157_beat_3-4.mid', '6_rock_88_beat_4-4.mid', '1_latin-brazilian-bossa_127_beat_4-4.mid', '1_rock_60_beat_4-4.mid', '1_rock_70_beat_6-8.mid', '1_rock_100_beat_4-4.mid', '1_rock_90_beat_4-4.mid', '1_rock_86_beat_4-4.mid', '1_rock_87_beat_4-4.mid', '1_rock_95_beat_4-4.mid', '1_rock_130_beat_4-4.mid', '1_rock_105_beat_4-4.mid', '1_rock_120_beat_4-4.mid', '1_rock_110_beat_4-4.mid', '1_rock-prog_125_beat_4-4.mid', '1_rock-shuffle_85_beat_4-4.mid', '2_latin-brazilian_101_beat_4-4.mid', '2_jazz-swing_185_beat_4-4.mid', '2_funk_95_beat_4-4.mid', '2_funk_80_beat_4-4.mid', '2_funk_92_beat_4-4.mid', '2_latin-brazilian-bossa_127_beat_4-4.mid', '2_jazz-swing_215_beat_4-4.mid', '2_jazz_158_beat_4-4.mid', '2_latin-chacarera_118_beat_4-4.mid', '2_rock_130_beat_4-4.mid', '2_rock_86_fill_4-4.mid', '2_rock_95_beat_4-4.mid', '2_rock_70_beat_6-8.mid', '2_rock_105_beat_4-4.mid', '2_rock_100_beat_4-4.mid', '2_rock_120_beat_4-4.mid', '2_rock_102_beat_4-4.mid', '2_rock_60_fill_4-4.mid', '3_afrobeat_114_beat_4-4.mid', '3_latin-chacarera_118_beat_4-4.mid', '3_jazz-swing_215_beat_4-4.mid', '3_jazz-klezmer_152_beat_4-4.mid', '3_hiphop_90_beat_4-4.mid', '3_latin-brazilian-samba_89_beat_4-4.mid', '3_funk_80_beat_4-4.mid', '3_latin-brazilian_101_beat_4-4.mid', '3_rock_60_fill_4-4.mid', '3_rock_80_beat_6-8.mid', '3_rock_86_fill_4-4.mid', '3_rock-rockabilly_200_beat_4-4.mid', '3_rock_130_beat_4-4.mid', '4_afrobeat_114_beat_4-4.mid', '3_rock_120_beat_4-4.mid', '3_rock_100_beat_4-4.mid', '3_rock_88_beat_4-4.mid', '3_rock_105_beat_4-4.mid', '4_jazz_120_beat_3-4.mid', '4_hiphop_90_beat_4-4.mid', '4_jazz-funk_116_beat_4-4.mid', '4_jazz-linear_182_beat_4-4.mid', '4_rock_80_beat_6-8.mid', '4_jazz-swing_215_beat_4-4.mid', '4_latin-brazilian_92_beat_4-4.mid', '4_rock_100_beat_4-4.mid', '4_reggae_141_beat_4-4.mid', '4_rock_86_fill_4-4.mid', '4_latin-brazilian-samba_89_beat_4-4.mid', '4_rock_60_fill_4-4.mid', '4_rock_105_beat_4-4.mid', '5_funk_91_beat_4-4.mid', '4_rock_130_beat_4-4.mid', '5_jazz-funk_116_beat_4-4.mid', '4_rock_120_beat_4-4.mid', '5_jazz-linear_128_beat_4-4.mid', '4_rock_127_beat_4-4.mid', '5_jazz_200_beat_3-4.mid', '5_hiphop_90_beat_4-4.mid', '5_jazz-swing_215_beat_4-4.mid', '5_latin-brazilian-samba_89_beat_4-4.mid', '5_latin-brazilian_184_beat_4-4.mid', '5_rock_60_beat_6-8.mid', '5_reggae_126_beat_4-4.mid', '5_rock_100_beat_4-4.mid', '5_rock_130_fill_4-4.mid', '5_rock_60_fill_4-4.mid', '5_rock_105_beat_4-4.mid', '5_rock_120_beat_4-4.mid', '5_rock_86_fill_4-4.mid']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JqVhsGvTszx",
        "colab_type": "text"
      },
      "source": [
        "# **progess()**\n",
        "Define a function that will display a progress bar so that we can monitor the progress of the parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u76DI2z47EXk",
        "colab_type": "code",
        "outputId": "1ba89859-c8de-4892-a727-8b5793b86bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "def progress(file, value, max=100):\n",
        "  return HTML(\"\"\"\n",
        "      <p>{file}</p>\n",
        "      <progress\n",
        "          value='{value}'\n",
        "          max='{max}',\n",
        "          style='width: 100%'\n",
        "      >\n",
        "          {value}\n",
        "      </progress>\n",
        "  \"\"\".format(file=file, value=value, max=max))\n",
        "\n",
        "out = display(progress(0, 100), display_id=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "      <p>0</p>\n",
              "      <progress\n",
              "          value='100'\n",
              "          max='100',\n",
              "          style='width: 100%'\n",
              "      >\n",
              "          100\n",
              "      </progress>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzRkvLjp05T0",
        "colab_type": "text"
      },
      "source": [
        "# **Parse the notes from the MIDI files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWeyoZU-0_j7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getNotes() :\n",
        "  DIR = '/content/gdrive/My Drive/MIDI'\n",
        "  num_files = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\n",
        "  notes = []\n",
        "  i = 1\n",
        "  for file in glob.glob(DIR + '/*.mid'):\n",
        "      # if 'rock' not in file:\n",
        "      #     continue\n",
        "\n",
        "      midi = converter.parse(file)\n",
        "\n",
        "      # print(\"Parsing %s\" % (i))\n",
        "      out.update(progress(file, i, num_files))\n",
        "      i = i + 1\n",
        "\n",
        "      notes_to_parse = None\n",
        "      parts = instrument.partitionByInstrument(midi)\n",
        "\n",
        "      if parts:\n",
        "          notes_to_parse = parts.parts[0].recurse()\n",
        "      else:\n",
        "          notes_to_parse = midi.flat.notes\n",
        "\n",
        "      for element in notes_to_parse:\n",
        "          if isinstance(element, note.Note):\n",
        "              notes.append(str(element.pitch))\n",
        "          elif isinstance(element, chord.Chord):\n",
        "              notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "      # if i > 15:\n",
        "      #     break\n",
        "\n",
        "  out.update(progress('COMPLETE', num_files, num_files))\n",
        "  with open('notes', 'wb') as filepath:\n",
        "      # write notes in binary format to filepath\n",
        "      pickle.dump(notes, filepath)\n",
        "  return notes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H5kO7V_8UMN",
        "colab_type": "text"
      },
      "source": [
        "# **Get the notes from the MIDI files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQcOiNS51eUY",
        "colab_type": "code",
        "outputId": "bc570d3a-e535-40ac-c9b8-778048cabc68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "notes = getNotes()\n",
        "print(str(len(notes)) + ' Total Notes')\n",
        "print(str(len(set(notes))) + ' Unique Notes')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "      <p>COMPLETE</p>\n",
              "      <progress\n",
              "          value='100'\n",
              "          max='100',\n",
              "          style='width: 100%'\n",
              "      >\n",
              "          100\n",
              "      </progress>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "83626 Total Notes\n",
            "208 Unique Notes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR8TeUheVfA8",
        "colab_type": "text"
      },
      "source": [
        "# **Set up helper values**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVjg5GPc7jts",
        "colab_type": "code",
        "outputId": "618b2dae-54b2-415a-9eb4-7ed610dc70c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "sequence_length = 500\n",
        "generator_input = 100\n",
        "total_notes = len(notes)\n",
        "unique_notes = len(set(notes))\n",
        "pitchnames = sorted(set(notes))\n",
        "print(pitchnames)\n",
        "note_to_int = dict( (note, number) for number, note in enumerate(pitchnames) )\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '0.1', '0.1.2', '0.1.2.3', '0.1.2.5', '0.1.3', '0.1.4', '0.1.6', '0.2', '0.2.3', '0.2.4', '0.2.4.8', '0.2.5', '0.2.5.8', '0.2.6', '0.2.7', '0.3', '0.3.4', '0.3.5', '0.3.7', '0.4', '0.4.5', '0.4.6', '0.4.7', '0.4.7.8', '0.4.8', '0.5', '0.6', '1.2', '1.2.3', '1.2.3.8', '1.2.5', '1.2.5.8', '1.2.6', '1.3', '1.3.8', '1.4', '1.5', '1.5.8', '1.6', '1.7', '10', '10.0', '10.0.1', '10.0.1.2', '10.0.2', '10.0.3', '10.0.4', '10.1', '10.1.2', '10.11.1.2', '10.11.2', '10.2', '10.2.3', '10.2.4', '10.3', '10.3.4', '11.0', '11.0.2', '11.0.3', '11.0.4', '11.1', '11.1.2', '11.1.2.3', '11.2', '11.3', '11.4', '2', '2.3', '2.3.8', '2.4', '2.4.6', '2.4.8', '2.4.8.10', '2.5', '2.5.8', '2.6', '2.6.8', '2.7', '2.7.8', '2.8', '3.4', '3.4.8', '3.4.8.10', '3.7', '3.7.8', '3.8', '3.8.9', '3.9', '4', '4.10', '4.5', '4.5.8', '4.6', '4.6.8', '4.7', '4.7.8', '4.8', '4.8.10', '4.8.11', '4.8.9', '4.9', '5.10', '5.7', '5.7.0', '5.7.8', '5.8', '5.8.0', '5.8.10', '5.9', '6.11', '6.7', '6.7.0', '6.8', '6.8.0', '6.8.1', '6.9', '7.0', '7.0.1', '7.10', '7.10.0', '7.11', '7.11.0', '7.8', '7.8.0', '7.8.0.2', '7.8.0.3', '7.8.1', '7.8.10', '7.8.10.0', '7.8.11', '7.8.11.0', '7.8.9', '7.9', '7.9.0', '8.0', '8.0.1', '8.0.1.2', '8.0.1.2.3', '8.0.1.3', '8.0.2', '8.0.2.3', '8.0.3', '8.1', '8.1.2', '8.10', '8.10.0', '8.10.0.1', '8.10.0.2', '8.10.0.2.3', '8.10.0.3', '8.10.0.4', '8.10.1', '8.10.1.2', '8.10.1.3', '8.10.11', '8.10.11.0', '8.10.11.2', '8.10.2', '8.10.2.3', '8.10.3', '8.11', '8.11.0', '8.11.0.2', '8.11.1', '8.11.1.2', '8.11.2', '8.11.2.3', '8.11.3', '8.9', '8.9.0', '8.9.0.2', '8.9.1', '8.9.10', '8.9.10.0', '8.9.10.2', '8.9.11', '8.9.2', '9.0', '9.0.1', '9.0.2', '9.0.3', '9.0.4', '9.10', '9.11', '9.2', 'A2', 'A3', 'B-0', 'B-2', 'B-3', 'B2', 'B3', 'C#2', 'C#3', 'C2', 'C3', 'D1', 'D2', 'D3', 'E-3', 'E2', 'E3', 'F#2', 'F3', 'G#2', 'G2', 'G3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1Wf13Kq9_KN",
        "colab_type": "text"
      },
      "source": [
        "# **Set up training input and targets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1_yI9RM-D9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainx = []\n",
        "trainy = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2XJplzo-NcU",
        "colab_type": "text"
      },
      "source": [
        "# **Prepare Training Sequences**\n",
        "Create arrays of *sequence_length* where the first sequence is\n",
        " *x* will be *notes[0:sequence_length]* and *notes\n",
        "\n",
        "*   x[0] will be notes[ 0 : sequence_length ]\n",
        "*   y[0] will be notes[ sequence_length ]\n",
        "\n",
        "Remembering that [0 : sequence_length] does not include the *sequence_length*th note. We need to put the next note in the sequence into y\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dDoQ7dz_uF4",
        "colab_type": "code",
        "outputId": "0c75a340-cbe6-4279-b8d5-967707c7866f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "for i in range( 0, total_notes - sequence_length ):\n",
        "  x_sequence = notes[i : i + sequence_length]\n",
        "  y_sequence = notes[i + sequence_length]\n",
        "  trainx.append( [ note_to_int[note] for note in x_sequence ] )\n",
        "  trainy.append(note_to_int[y_sequence])\n",
        "\n",
        "n_sequences = len(trainx)\n",
        "print('Number of sequences: ' + str(n_sequences))\n",
        "print('Sequence 1: ' + str(trainx[0][0]))\n",
        "print('Sequence 1 output: ' + str(trainy[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 83126\n",
            "Sequence 1: 188\n",
            "Sequence 1 output: 195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lvICyr2IN_M",
        "colab_type": "text"
      },
      "source": [
        "# **Normalize the Sequences**\n",
        "Normalize the sequences so that each note is between 0 and 1. Convert the output values to categorical one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8eFhgTIUkg",
        "colab_type": "code",
        "outputId": "b80ab727-cb15-41fa-9483-79f44142fb0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(trainx[0][0:10])\n",
        "trainx = np.reshape(trainx, (n_sequences, sequence_length, 1))\n",
        "print('trainx shape: ' + str(trainx.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[188, 197, 197, 201, 195, 117, 197, 195, 70, 8]\n",
            "trainx shape: (83126, 500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WP1LBARI_BI",
        "colab_type": "code",
        "outputId": "bfceab8f-478b-4a15-8ea3-835d2545e817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "# trainx = (trainx) / float(unique_notes)\n",
        "trainy = np_utils.to_categorical(trainy)\n",
        "\n",
        "latent_size = (trainx.shape[1], trainx.shape[2])\n",
        "\n",
        "print('Index of category: ' + str(np.argmax(trainy[0])))\n",
        "print(trainx[0][0:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of category: 195\n",
            "[[188]\n",
            " [197]\n",
            " [197]\n",
            " [201]\n",
            " [195]\n",
            " [117]\n",
            " [197]\n",
            " [195]\n",
            " [ 70]\n",
            " [  8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3PTdduiuwaN",
        "colab_type": "text"
      },
      "source": [
        "# **Build the Generator and Discriminator for the GAN**\n",
        "Discriminator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Z_yuxKu00m",
        "colab_type": "code",
        "outputId": "9a5ca0c6-c16d-48ee-a8a1-290a60da3760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        }
      },
      "source": [
        "discriminator = Sequential()\n",
        "discriminator.add(CuDNNLSTM(512, input_shape=latent_size, return_sequences=True))\n",
        "discriminator.add(Bidirectional(CuDNNLSTM(512)))\n",
        "discriminator.add(Dense(512))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dense(256))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dense(128))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dense(64))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "discriminator.trainable = False\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 500, 512)          1054720   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1024)              4202496   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,954,561\n",
            "Trainable params: 0\n",
            "Non-trainable params: 5,954,561\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DVnRusGxwdl",
        "colab_type": "text"
      },
      "source": [
        "Generator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LsGswvCxwBV",
        "colab_type": "code",
        "outputId": "38b7ed28-abd8-469d-f53e-ab1181a6bb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "generator = Sequential()\n",
        "generator.add(Dense(256, input_dim=generator_input))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "generator.add(Dense(512))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "generator.add(Dense(1024))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "generator.add(Dense(np.prod((trainx.shape[1], trainx.shape[2])), activation='tanh'))\n",
        "generator.add(Reshape(latent_size))\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 500)               512500    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 500, 1)            0         \n",
            "=================================================================\n",
            "Total params: 1,202,420\n",
            "Trainable params: 1,198,836\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1VfRmEiWPML",
        "colab_type": "code",
        "outputId": "b5252be0-7d96-411b-9607-de7a2c7361c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# adversary = Sequential()\n",
        "# adversary.add(generator)\n",
        "# adversary.add(discriminator)\n",
        "\n",
        "# adversary.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# discriminator.trainable = False\n",
        "\n",
        "gan_input = Input(shape=(generator_input,))\n",
        "fake_seq = generator(gan_input)\n",
        "\n",
        "gan_output = discriminator(fake_seq)\n",
        "\n",
        "gan = Model(gan_input, gan_output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "gan.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 500, 1)            1202420   \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 1)                 5954561   \n",
            "=================================================================\n",
            "Total params: 7,156,981\n",
            "Trainable params: 1,198,836\n",
            "Non-trainable params: 5,958,145\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjb0EOhEDoUd",
        "colab_type": "text"
      },
      "source": [
        "# **Feed noise through generator**\n",
        "generate a random batch from the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM5ZrCBpAYXL",
        "colab_type": "code",
        "outputId": "5cc0afe5-1471-42fa-a8fb-a150da587125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 124\n",
        "x_batch = trainx[ np.random.randint(0, trainx.shape[0], size=batch_size), : ]\n",
        "print(x_batch[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 45]\n",
            " [203]\n",
            " [198]\n",
            " [ 42]\n",
            " [ 90]\n",
            " [203]\n",
            " [ 42]\n",
            " [ 52]\n",
            " [198]\n",
            " [203]\n",
            " [195]\n",
            " [188]\n",
            " [ 52]\n",
            " [198]\n",
            " [203]\n",
            " [195]\n",
            " [188]\n",
            " [198]\n",
            " [  8]\n",
            " [198]\n",
            " [195]\n",
            " [197]\n",
            " [205]\n",
            " [ 76]\n",
            " [203]\n",
            " [  8]\n",
            " [205]\n",
            " [ 90]\n",
            " [189]\n",
            " [  8]\n",
            " [205]\n",
            " [ 90]\n",
            " [203]\n",
            " [  8]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [193]\n",
            " [  8]\n",
            " [205]\n",
            " [ 52]\n",
            " [188]\n",
            " [  8]\n",
            " [205]\n",
            " [ 90]\n",
            " [203]\n",
            " [  8]\n",
            " [205]\n",
            " [ 52]\n",
            " [203]\n",
            " [  8]\n",
            " [ 98]\n",
            " [203]\n",
            " [  8]\n",
            " [205]\n",
            " [ 90]\n",
            " [189]\n",
            " [  8]\n",
            " [205]\n",
            " [ 90]\n",
            " [203]\n",
            " [  8]\n",
            " [205]\n",
            " [ 90]\n",
            " [203]\n",
            " [  8]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [201]\n",
            " [  8]\n",
            " [205]\n",
            " [ 93]\n",
            " [203]\n",
            " [195]\n",
            " [197]\n",
            " [143]\n",
            " [188]\n",
            " [203]\n",
            " [  8]\n",
            " [205]\n",
            " [198]\n",
            " [198]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [201]\n",
            " [205]\n",
            " [198]\n",
            " [201]\n",
            " [117]\n",
            " [ 70]\n",
            " [198]\n",
            " [  8]\n",
            " [205]\n",
            " [ 52]\n",
            " [203]\n",
            " [  8]\n",
            " [ 70]\n",
            " [189]\n",
            " [  8]\n",
            " [195]\n",
            " [ 70]\n",
            " [189]\n",
            " [197]\n",
            " [195]\n",
            " [ 70]\n",
            " [189]\n",
            " [  8]\n",
            " [ 70]\n",
            " [189]\n",
            " [  8]\n",
            " [ 67]\n",
            " [189]\n",
            " [  8]\n",
            " [195]\n",
            " [ 70]\n",
            " [197]\n",
            " [  8]\n",
            " [ 70]\n",
            " [189]\n",
            " [  8]\n",
            " [ 70]\n",
            " [189]\n",
            " [  8]\n",
            " [ 67]\n",
            " [ 28]\n",
            " [  8]\n",
            " [195]\n",
            " [ 67]\n",
            " [189]\n",
            " [  8]\n",
            " [ 70]\n",
            " [197]\n",
            " [195]\n",
            " [195]\n",
            " [ 67]\n",
            " [198]\n",
            " [ 80]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [198]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [198]\n",
            " [198]\n",
            " [ 20]\n",
            " [ 80]\n",
            " [198]\n",
            " [  0]\n",
            " [ 25]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [195]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [ 25]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [198]\n",
            " [195]\n",
            " [205]\n",
            " [201]\n",
            " [201]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [195]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [198]\n",
            " [  0]\n",
            " [196]\n",
            " [206]\n",
            " [205]\n",
            " [206]\n",
            " [206]\n",
            " [ 20]\n",
            " [ 80]\n",
            " [201]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [ 25]\n",
            " [198]\n",
            " [  0]\n",
            " [195]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [195]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [195]\n",
            " [205]\n",
            " [ 20]\n",
            " [198]\n",
            " [  0]\n",
            " [ 97]\n",
            " [196]\n",
            " [198]\n",
            " [140]\n",
            " [198]\n",
            " [140]\n",
            " [198]\n",
            " [136]\n",
            " [198]\n",
            " [198]\n",
            " [198]\n",
            " [135]\n",
            " [198]\n",
            " [198]\n",
            " [198]\n",
            " [135]\n",
            " [198]\n",
            " [201]\n",
            " [135]\n",
            " [198]\n",
            " [201]\n",
            " [ 20]\n",
            " [ 96]\n",
            " [195]\n",
            " [205]\n",
            " [ 89]\n",
            " [195]\n",
            " [205]\n",
            " [ 95]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [ 97]\n",
            " [201]\n",
            " [198]\n",
            " [195]\n",
            " [205]\n",
            " [ 78]\n",
            " [198]\n",
            " [195]\n",
            " [ 97]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [ 96]\n",
            " [193]\n",
            " [195]\n",
            " [195]\n",
            " [ 97]\n",
            " [193]\n",
            " [195]\n",
            " [123]\n",
            " [201]\n",
            " [195]\n",
            " [ 97]\n",
            " [195]\n",
            " [123]\n",
            " [201]\n",
            " [195]\n",
            " [195]\n",
            " [205]\n",
            " [ 89]\n",
            " [195]\n",
            " [205]\n",
            " [ 95]\n",
            " [195]\n",
            " [195]\n",
            " [205]\n",
            " [ 89]\n",
            " [195]\n",
            " [205]\n",
            " [ 95]\n",
            " [198]\n",
            " [  8]\n",
            " [196]\n",
            " [196]\n",
            " [205]\n",
            " [196]\n",
            " [206]\n",
            " [206]\n",
            " [205]\n",
            " [ 20]\n",
            " [205]\n",
            " [ 95]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [ 97]\n",
            " [198]\n",
            " [195]\n",
            " [123]\n",
            " [198]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [ 97]\n",
            " [201]\n",
            " [198]\n",
            " [195]\n",
            " [123]\n",
            " [201]\n",
            " [195]\n",
            " [195]\n",
            " [ 97]\n",
            " [201]\n",
            " [201]\n",
            " [195]\n",
            " [195]\n",
            " [123]\n",
            " [201]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [ 97]\n",
            " [198]\n",
            " [195]\n",
            " [205]\n",
            " [ 95]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [205]\n",
            " [ 89]\n",
            " [198]\n",
            " [195]\n",
            " [205]\n",
            " [ 95]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [ 97]\n",
            " [201]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [123]\n",
            " [201]\n",
            " [198]\n",
            " [195]\n",
            " [195]\n",
            " [ 97]\n",
            " [202]\n",
            " [198]\n",
            " [205]\n",
            " [195]\n",
            " [198]\n",
            " [ 80]\n",
            " [195]\n",
            " [198]\n",
            " [ 80]\n",
            " [195]\n",
            " [199]\n",
            " [196]\n",
            " [123]\n",
            " [206]\n",
            " [195]\n",
            " [ 57]\n",
            " [ 97]\n",
            " [198]\n",
            " [195]\n",
            " [200]\n",
            " [195]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [ 16]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [ 16]\n",
            " [ 97]\n",
            " [192]\n",
            " [198]\n",
            " [ 16]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [195]\n",
            " [200]\n",
            " [205]\n",
            " [ 81]\n",
            " [193]\n",
            " [ 57]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [195]\n",
            " [200]\n",
            " [195]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [ 16]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [195]\n",
            " [200]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [ 16]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [195]\n",
            " [200]\n",
            " [195]\n",
            " [205]\n",
            " [ 81]\n",
            " [198]\n",
            " [ 16]\n",
            " [195]\n",
            " [205]\n",
            " [ 66]\n",
            " [198]\n",
            " [195]\n",
            " [200]\n",
            " [205]\n",
            " [ 66]\n",
            " [198]\n",
            " [ 57]\n",
            " [198]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [198]\n",
            " [205]\n",
            " [198]\n",
            " [198]\n",
            " [198]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW8_jlBYFKAb",
        "colab_type": "text"
      },
      "source": [
        "generate fake data from a sequence of noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMkTrrSfFFRU",
        "colab_type": "code",
        "outputId": "bc526ff2-b881-4320-9b41-37abadc983e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "prog = display(progress(0, 100), display_id=True)\n",
        "epochs = 400\n",
        "steps_per_batch = 32\n",
        "g_loss = -1\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "  for batch in range(steps_per_batch):\n",
        "    noise = np.random.uniform( 0, 1, size=[batch_size, 100] )\n",
        "    fake = generator.predict(noise)\n",
        "    x_batch = trainx[ np.random.randint(0, trainx.shape[0], size=batch_size), : ]\n",
        "    x = np.concatenate((x_batch, fake))\n",
        "    y = np.zeros([2*batch_size, 1])\n",
        "    y[:batch_size, :] = 0.9\n",
        "    y[batch_size:, :] = 0\n",
        "    d_loss = discriminator.train_on_batch(x, y)\n",
        "    y_gen = np.ones(batch_size)\n",
        "    g_loss = gan.train_on_batch(noise, y_gen)\n",
        "    prog.update(progress('Epoch ' + str(epoch+1) + ' (batch ' + str(batch) + ') D loss: ' + str(d_loss), epoch, epochs - 1))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "      <p>Epoch 400 (batch 31) D loss: 0.654752</p>\n",
              "      <progress\n",
              "          value='399'\n",
              "          max='399',\n",
              "          style='width: 100%'\n",
              "      >\n",
              "          399\n",
              "      </progress>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LObrJD_Hm0X3",
        "colab_type": "code",
        "outputId": "f95e6432-5e2b-46ae-aed8-37589668bd69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "noise = np.random.uniform( 0, 1, size=[batch_size, 100] )\n",
        "# print((noise*float(unique_notes)).astype(int)[0])\n",
        "# print(noise.shape)\n",
        "fake = generator.predict(noise)\n",
        "fake = (fake)*float(unique_notes)\n",
        "fake = np.absolute(fake.astype(int))\n",
        "print(fake[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [185]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [206]\n",
            " [207]\n",
            " [206]\n",
            " [206]\n",
            " [206]\n",
            " [206]\n",
            " [205]\n",
            " [196]\n",
            " [206]\n",
            " [204]\n",
            " [205]\n",
            " [198]\n",
            " [202]\n",
            " [205]\n",
            " [205]\n",
            " [206]\n",
            " [205]\n",
            " [206]\n",
            " [179]\n",
            " [181]\n",
            " [203]\n",
            " [171]\n",
            " [204]\n",
            " [196]\n",
            " [203]\n",
            " [187]\n",
            " [182]\n",
            " [199]\n",
            " [185]\n",
            " [165]\n",
            " [202]\n",
            " [198]\n",
            " [186]\n",
            " [187]\n",
            " [163]\n",
            " [176]\n",
            " [150]\n",
            " [142]\n",
            " [101]\n",
            " [ 15]\n",
            " [170]\n",
            " [ 98]\n",
            " [ 34]\n",
            " [ 48]\n",
            " [ 64]\n",
            " [ 73]\n",
            " [ 90]\n",
            " [ 23]\n",
            " [ 62]\n",
            " [ 38]\n",
            " [  2]\n",
            " [105]\n",
            " [ 94]\n",
            " [188]\n",
            " [123]\n",
            " [ 31]\n",
            " [133]\n",
            " [160]\n",
            " [135]\n",
            " [ 55]\n",
            " [ 35]\n",
            " [  0]\n",
            " [ 50]\n",
            " [ 61]\n",
            " [ 77]\n",
            " [ 61]\n",
            " [193]\n",
            " [152]\n",
            " [ 60]\n",
            " [163]\n",
            " [122]\n",
            " [ 75]\n",
            " [ 41]\n",
            " [  5]\n",
            " [172]\n",
            " [ 91]\n",
            " [110]\n",
            " [ 26]\n",
            " [ 70]\n",
            " [121]\n",
            " [172]\n",
            " [117]\n",
            " [141]\n",
            " [  5]\n",
            " [ 77]\n",
            " [  4]\n",
            " [142]\n",
            " [ 24]\n",
            " [165]\n",
            " [ 33]\n",
            " [ 70]\n",
            " [115]\n",
            " [149]\n",
            " [ 72]\n",
            " [ 52]\n",
            " [138]\n",
            " [ 66]\n",
            " [ 11]\n",
            " [ 61]\n",
            " [154]\n",
            " [ 82]\n",
            " [ 68]\n",
            " [115]\n",
            " [ 98]\n",
            " [ 66]\n",
            " [ 38]\n",
            " [164]\n",
            " [ 86]\n",
            " [132]\n",
            " [ 95]\n",
            " [145]\n",
            " [ 46]\n",
            " [ 62]\n",
            " [ 15]\n",
            " [ 93]\n",
            " [ 13]\n",
            " [ 55]\n",
            " [ 86]\n",
            " [ 74]\n",
            " [ 26]\n",
            " [ 32]\n",
            " [112]\n",
            " [ 52]\n",
            " [159]\n",
            " [163]\n",
            " [123]\n",
            " [ 84]\n",
            " [157]\n",
            " [124]\n",
            " [ 51]\n",
            " [ 11]\n",
            " [149]\n",
            " [ 85]\n",
            " [ 82]\n",
            " [ 23]\n",
            " [108]\n",
            " [148]\n",
            " [179]\n",
            " [ 75]\n",
            " [129]\n",
            " [139]\n",
            " [ 41]\n",
            " [ 34]\n",
            " [ 69]\n",
            " [158]\n",
            " [107]\n",
            " [ 92]\n",
            " [ 49]\n",
            " [ 83]\n",
            " [ 78]\n",
            " [121]\n",
            " [  3]\n",
            " [113]\n",
            " [ 22]\n",
            " [ 22]\n",
            " [143]\n",
            " [ 55]\n",
            " [ 35]\n",
            " [ 11]\n",
            " [ 53]\n",
            " [ 74]\n",
            " [ 63]\n",
            " [ 95]\n",
            " [ 60]\n",
            " [ 66]\n",
            " [102]\n",
            " [ 42]\n",
            " [ 91]\n",
            " [104]\n",
            " [  6]\n",
            " [151]\n",
            " [ 15]\n",
            " [126]\n",
            " [104]\n",
            " [123]\n",
            " [ 79]\n",
            " [ 72]\n",
            " [ 55]\n",
            " [ 58]\n",
            " [ 55]\n",
            " [109]\n",
            " [112]\n",
            " [ 46]\n",
            " [ 95]\n",
            " [ 17]\n",
            " [ 84]\n",
            " [  1]\n",
            " [ 31]\n",
            " [ 52]\n",
            " [110]\n",
            " [168]\n",
            " [155]\n",
            " [ 15]\n",
            " [103]\n",
            " [ 97]\n",
            " [110]\n",
            " [ 75]\n",
            " [ 62]\n",
            " [140]\n",
            " [ 66]\n",
            " [ 79]\n",
            " [ 39]\n",
            " [115]\n",
            " [107]\n",
            " [ 19]\n",
            " [ 74]\n",
            " [ 34]\n",
            " [  9]\n",
            " [186]\n",
            " [ 87]\n",
            " [190]\n",
            " [120]\n",
            " [126]\n",
            " [129]\n",
            " [  2]\n",
            " [131]\n",
            " [ 19]\n",
            " [109]\n",
            " [ 36]\n",
            " [ 32]\n",
            " [ 64]\n",
            " [ 70]\n",
            " [ 50]\n",
            " [ 39]\n",
            " [ 98]\n",
            " [109]\n",
            " [137]\n",
            " [129]\n",
            " [ 60]\n",
            " [ 91]\n",
            " [177]\n",
            " [  3]\n",
            " [109]\n",
            " [ 43]\n",
            " [132]\n",
            " [142]\n",
            " [ 55]\n",
            " [ 21]\n",
            " [124]\n",
            " [ 23]\n",
            " [  3]\n",
            " [  4]\n",
            " [ 42]\n",
            " [173]\n",
            " [125]\n",
            " [ 47]\n",
            " [  4]\n",
            " [ 89]\n",
            " [120]\n",
            " [171]\n",
            " [ 91]\n",
            " [ 50]\n",
            " [117]\n",
            " [ 55]\n",
            " [ 73]\n",
            " [  3]\n",
            " [ 58]\n",
            " [103]\n",
            " [101]\n",
            " [110]\n",
            " [112]\n",
            " [ 80]\n",
            " [106]\n",
            " [ 84]\n",
            " [166]\n",
            " [ 75]\n",
            " [ 17]\n",
            " [ 15]\n",
            " [122]\n",
            " [ 57]\n",
            " [ 70]\n",
            " [101]\n",
            " [ 42]\n",
            " [ 19]\n",
            " [ 47]\n",
            " [ 64]\n",
            " [ 64]\n",
            " [132]\n",
            " [181]\n",
            " [ 57]\n",
            " [129]\n",
            " [185]\n",
            " [ 61]\n",
            " [114]\n",
            " [ 66]\n",
            " [148]\n",
            " [102]\n",
            " [158]\n",
            " [ 31]\n",
            " [ 90]\n",
            " [ 28]\n",
            " [187]\n",
            " [ 18]\n",
            " [ 38]\n",
            " [ 32]\n",
            " [ 48]\n",
            " [118]\n",
            " [124]\n",
            " [ 36]\n",
            " [148]\n",
            " [ 76]\n",
            " [146]\n",
            " [ 18]\n",
            " [128]\n",
            " [ 39]\n",
            " [ 63]\n",
            " [ 90]\n",
            " [  0]\n",
            " [ 54]\n",
            " [115]\n",
            " [  4]\n",
            " [121]\n",
            " [ 53]\n",
            " [ 12]\n",
            " [ 41]\n",
            " [152]\n",
            " [ 25]\n",
            " [ 87]\n",
            " [118]\n",
            " [114]\n",
            " [151]\n",
            " [ 61]\n",
            " [  2]\n",
            " [  1]\n",
            " [133]\n",
            " [ 98]\n",
            " [ 47]\n",
            " [  6]\n",
            " [ 56]\n",
            " [ 58]\n",
            " [ 24]\n",
            " [ 40]\n",
            " [ 94]\n",
            " [181]\n",
            " [176]\n",
            " [171]\n",
            " [115]\n",
            " [167]\n",
            " [179]\n",
            " [148]\n",
            " [185]\n",
            " [197]\n",
            " [198]\n",
            " [152]\n",
            " [195]\n",
            " [191]\n",
            " [202]\n",
            " [191]\n",
            " [184]\n",
            " [191]\n",
            " [202]\n",
            " [196]\n",
            " [205]\n",
            " [200]\n",
            " [202]\n",
            " [204]\n",
            " [203]\n",
            " [203]\n",
            " [202]\n",
            " [203]\n",
            " [206]\n",
            " [206]\n",
            " [200]\n",
            " [202]\n",
            " [205]\n",
            " [206]\n",
            " [206]\n",
            " [204]\n",
            " [206]\n",
            " [207]\n",
            " [206]\n",
            " [205]\n",
            " [205]\n",
            " [204]\n",
            " [205]\n",
            " [206]\n",
            " [206]\n",
            " [200]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [180]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]\n",
            " [207]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY6BflJZQ8SO",
        "colab_type": "text"
      },
      "source": [
        "# Generate MIDI file\n",
        "Use the notes from the generated fake sequence to create a MIDI file to hear the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX65URrwRJOk",
        "colab_type": "code",
        "outputId": "9b31aa4a-8ec8-476f-d5d5-340c79438941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "offset = 0\n",
        "output_notes = []\n",
        "output = []\n",
        "# for i in range(len(x_batch[0])):\n",
        "#   output.append(x_batch[0][i][0])\n",
        "for i in range(len(fake)):\n",
        "  output.append(fake[0][i][0])\n",
        "\n",
        "print(output)\n",
        "# create note and chord objects based on the values generated by the model\n",
        "for pattern in output:\n",
        "    # pattern is a chord\n",
        "    if pattern > 357:\n",
        "      pattern = 357\n",
        "    n = int_to_note[pattern]\n",
        "    if ('.' in n) or n.isdigit():\n",
        "        notes_in_chord = n.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    # pattern is a note\n",
        "    else:\n",
        "        new_note = note.Note(n)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='/content/gdrive/My Drive/GAN DRUM OUTPUT/test_output2.mid')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-48baac7b2e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for i in range(len(x_batch[0])):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#   output.append(x_batch[0][i][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fake' is not defined"
          ]
        }
      ]
    }
  ]
}